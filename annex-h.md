# Annex-H: Explainability Report Template

## 1. System Information
- **AI System Name:**  
- **Version/Model:**  
- **Business Unit:**  
- **Type of AI:** (generative text, image, code, etc.)
- **Deployment Environment:**  
- **Date of Report:**  
- **Report Prepared By:**  

## 2. Model Overview
- **Model Architecture:**  
- **Training Dataset Summary:**  
- **Key Parameters:**  
- **Performance Metrics:**  

## 3. Decision-Making Process

### 3.1 Feature Importance
| Feature | Importance Score | Role in Decision-Making |
|---------|-----------------|------------------------|
|  |  |  |
|  |  |  |
|  |  |  |

### 3.2 Decision Logic Explanation
_Provide a clear, non-technical explanation of how the system processes inputs to produce outputs:_

### 3.3 Confidence Levels
- **Confidence Scoring Methodology:**  
- **Typical Confidence Range:**  
- **Thresholds for Human Review:**  

## 4. Limitations and Constraints

### 4.1 Known Model Limitations
| Limitation | Description | Potential Impact | Mitigation |
|------------|-------------|-----------------|------------|
|  |  |  |  |
|  |  |  |  |
|  |  |  |  |

### 4.2 Edge Cases and Exceptions
| Edge Case | System Behavior | Recommended Response |
|-----------|----------------|---------------------|
|  |  |  |
|  |  |  |
|  |  |  |

### 4.3 Context Sensitivity
_Describe how changes in context can affect the system's outputs:_

## 5. Example Explanations
_Provide illustrative examples of system outputs with explanations:_

### Example 1
- **Input:**  
- **Output:**  
- **Explanation:**  
- **Key Factors:**  
- **Confidence Score:**  

### Example 2
- **Input:**  
- **Output:**  
- **Explanation:**  
- **Key Factors:**  
- **Confidence Score:**  

## 6. Human Oversight Integration

### 6.1 Review Triggers
| Trigger | Threshold | Expected Action |
|---------|-----------|----------------|
|  |  |  |
|  |  |  |
|  |  |  |

### 6.2 Override Mechanisms
_Describe how and when human operators can override the system:_

### 6.3 Feedback Loop Process
_Explain how human feedback is incorporated to improve the system:_

## 7. Stakeholder-Specific Explanations

### 7.1 For End Users
_Provide simplified explanation suitable for end users:_

### 7.2 For Technical Teams
_Provide technical details relevant for engineering/IT teams:_

### 7.3 For Compliance/Legal
_Provide regulatory and compliance-focused explanation:_

## 8. Testing and Validation

### 8.1 Explainability Testing
| Test Type | Date | Result | Issues | Resolution |
|-----------|------|--------|--------|------------|
|  |  |  |  |  |
|  |  |  |  |  |
|  |  |  |  |  |

### 8.2 User Comprehension Testing
_Results from testing whether explanations are understood by target audience:_

## 9. Documentation and References
- **Technical Documentation:**  
- **Model Cards:**  
- **Research Papers:**  
- **Related Policies:**  

## 10. Approval
| Role | Name | Approval Date | Signature |
|------|------|--------------|-----------|
| AI System Owner |  |  |  |
| Technical Reviewer |  |  |  |
| Ethics Board |  |  |  |
| Legal/Compliance |  |  |  |

**Next Explainability Review Due:** ____/____/20__