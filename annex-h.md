# Annex-H: Explainability Report Template

## 1. Report Metadata
- **AI System Name:**  
- **Business Unit:**  
- **Model Version:**  
- **Date of Report:**  
- **Prepared By:**  
- **Reviewed By (AI Ethics Board):**  

## 2. Use Case Description
- **Purpose of the AI System:**  
- **Stakeholders Affected:**  
- **Decision Type (e.g., classification, scoring, generation):**  
- **Human-in-the-Loop? (Yes/No):**  

## 3. Model Overview
- **Model Type:** (e.g., LLM, CNN, Transformer)  
- **Training Data Source:**  
- **Input Features Used:**  
- **Target Variable:**  
- **Output Format:**  

## 4. Explanation Methodology
| Technique | Description | Tool Used |
|-----------|-------------|-----------|
| Feature Importance | Shows which input features most influence output |             |
| SHAP/LIME | Local interpretability method used |             |
| Attention Maps | Visual explanation for text/image models |             |
| Confidence Scores | Probability estimates per prediction |             |
| Example-Based Explanation | Compares decision to similar past inputs |             |

## 5. Example Explanation
- **Input Data Sample:**  
- **Model Output:**  
- **Explanation of Output:**  
- **Confidence Score:**  
- **Top Contributing Features:**  
- **Any Overrides? (If yes, explain rationale):**  

## 6. Bias Check Summary
- **Bias Mitigation Applied:** (Yes/No)  
- **Disparities Detected:** (Y/N â€” explain by demographic group)  
- **Remediation Actions Taken:**  

## 7. Stakeholder Review
- **Was the explanation reviewed with affected stakeholders?** (Yes/No)  
- **Stakeholder Comments:**  
- **Changes made based on feedback:**  

## 8. Reviewer Sign-Off
| Name | Role | Signature | Date |
|------|------|-----------|------|
|      |      |           |      |