# Definitions & Glossary

This glossary defines key terms used throughout the policy to ensure common understanding.

|     |     |     |
| --- | --- | --- |
| **Term** | **Definition** | **Explanation/Context** |
| Generative AI | AI models that create new content (text, images, code, audio) from learned patterns | Includes large language models (LLMs) and generative image/audio tools used internally or externally. |
| High&hyphen;Risk AI | AI systems classified as high risk under the EU AI Act due to potential impact on fundamental rights | Examples include AI used in HR evaluations, safety-critical operations, or customer decision-making. |
| Data Protection Impact Assessment (DPIA) | Structured assessment to identify and mitigate privacy risks in processing personal data | Mandatory under GDPR for high-risk AI systems; uses Annex A template. |
| Bias Audit | Systematic review of training data and AI outputs to detect and remediate discriminatory patterns | Ensures fairness across protected attributes (gender, ethnicity, etc.). |
| Risk Tier | Classification of AI systems (low, medium, high) per EU AI Act criteria | Determines level of governance, documentation, and oversight required. |
| Model Provenance | Record of a model&rsquo;s origin, training data sources, version history, and ownership | Critical for traceability, compliance, and IP management. |
| Large Language Model (LLM) | A generative AI model trained on large text corpora to generate human-like text | Used for chatbots, support responses, and content generation. |
| Explainability | Ability to provide understandable rationale for AI-driven decisions | Required for transparency, stakeholder trust, and regulatory compliance. |
| Adversarial Testing | Simulated attacks against AI systems to identify vulnerabilities | Ensures robustness and security against malicious manipulation. |
| Sustainability Metrics | Measurements of AI systems� energy consumption and carbon emissions | Required under EU Green Deal for environmental reporting. |
| Human-in-the-Loop | Process design where humans review or approve AI outputs before final action | Safeguards against erroneous or harmful automated decisions. |
| Override Mechanism | Defined process enabling human operators to reject or amend AI decisions | Ensures ultimate human control over AI outcomes. |
| Data Minimisation | Principle of collecting only the minimum data necessary for a specified purpose | Reduces privacy risks and supports GDPR compliance. |
| Anonymisation | Irreversible process removing personal identifiers from data | Mitigates privacy risks while preserving data utility for analysis. |
| Pseudonymisation | Process replacing identifying fields with artificial identifiers | Reduces re-identification risk while allowing controlled data linkage. |
| Intellectual Property (IP) Clearance | Verification of ownership and licensing rights for data, models, and outputs | Prevents infringement and clarifies usage rights. |
| Compliance Register | Central log tracking AI systems, risk classifications, assessments, and approvals | Facilitates auditability and regulatory reporting. |
| Decision Rationale | Documentation of the reasoning behind AI-driven decisions | Supports explainability and accountability. |
| Incident Response Playbook | Formalized procedures for identifying, reporting, and resolving AI-related incidents | Ensures timely and coordinated response to breaches or failures. |
| Vendor Due Diligence | Process of evaluating third-party AI providers for compliance with policy and legal standards | Includes security, privacy, IP, and ethical risk assessments. |
| Stakeholder Engagement | Activities to gather input and feedback from employees, customers, regulators, and partners | Builds trust and informs policy improvements. |
| WCAG 2.1 AA | Accessibility standard ensuring digital content is perceivable, operable, understandable, and robust | Applies to AI-driven user interfaces and outputs. |
| Transparency | Clear communication about AI usage, capabilities, limitations, and decision-making processes | Required for ethical practice and regulatory compliance. |

---

[← Purpose & Scope](02-Purpose-and-Scope.md) | [Table of Contents](00-Table-of-Contents.md) | [Regulatory Compliance →](04-Regulatory-Compliance.md)
